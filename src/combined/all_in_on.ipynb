{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTQe_e8rh07M"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0VwbccebmbF",
        "outputId": "a5033ced-7761-4363-b008-c8d4dad929d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\denni\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List, Dict\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# use nltk for list of stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "%pip install wordcloud\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLzOcxTThy7t"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAl_h2DxbmbI"
      },
      "outputs": [],
      "source": [
        "def load_page(url:str) -> List[dict]:\n",
        "    '''\n",
        "    Load html content from requested Wikipedia page using \n",
        "    Wikipedia's API and separate them into sections.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of requested Wikipedia page to parse\n",
        "    \n",
        "    Returns:\n",
        "        List[dict]: List of dictionaries. Each dictionary contains\n",
        "          the parsed plain-text and hyperlinks for the section.\n",
        "    '''\n",
        "\n",
        "    parsed_sections = []\n",
        "\n",
        "    # use Wikipedia's API to get page content\n",
        "    page_name = url.split('/')[-1]\n",
        "\n",
        "    # get title and index of every section of requested Wikipedia page\n",
        "    response = requests.get(f'https://en.wikipedia.org/w/api.php?action=parse&prop=sections&format=json&page={page_name}')\n",
        "    response = response.json()['parse']['sections']\n",
        "    for section_metadata in response:\n",
        "        section = dict()\n",
        "        section['title'] = section_metadata['line']\n",
        "        section['index'] = section_metadata['index']\n",
        "        parsed_sections.append(section)\n",
        "\n",
        "    for section in parsed_sections:\n",
        "        # get html extract of page content from Wikipedia's API\n",
        "        response = requests.get(f\"https://en.wikipedia.org/w/api.php?action=parse&section={section['index']}&prop=text&format=json&page={page_name}\")\n",
        "        response = response.json()['parse']['text']['*']\n",
        "\n",
        "        # parse html extract using BeautifulSoup\n",
        "        parsed_html = BeautifulSoup(response, features='lxml')\n",
        "        text = []\n",
        "        hyperlinks = []\n",
        "        for p in parsed_html.find_all('p'):\n",
        "            # parse plain-text for each section\n",
        "            parsed_text = p.getText()\n",
        "            parsed_text = re.sub(r'(\\[(.*?)\\])+', '', parsed_text)  # remove citation tags\n",
        "            parsed_text = parsed_text.replace('\\n', ' ')            # remove new line character between paragraphs\n",
        "            parsed_text = parsed_text.replace('\\'', \"'\")\n",
        "            text.append(parsed_text)\n",
        "\n",
        "            # parse hyperlinks for each section\n",
        "            for a in p.find_all('a', href=True):\n",
        "                # avoid citation notes\n",
        "                path = a['href']\n",
        "                if '#cite_note' not in path:\n",
        "                    hyperlinks.append(path)\n",
        "\n",
        "        text = ''.join(text)\n",
        "        section['text'] = text\n",
        "\n",
        "        hyperlinks = [f'https://en.wikipedia.org/{i}' for i in hyperlinks]\n",
        "        section['hyperlinks'] = hyperlinks\n",
        "\n",
        "    return parsed_sections\n",
        "\n",
        "def digest_page(parsed_sections:List[Dict]) -> List[Dict]:\n",
        "    '''\n",
        "    Digest parsed section by removing stop words and punctuation; then computing \n",
        "    the frequency of words for each section.\n",
        "\n",
        "    Args:\n",
        "        parsed_section (List[Dict]): List of dictionaries. Each dictionary \n",
        "          contains the parsed plain-text and hyperlinks for the section.\n",
        "\n",
        "    Returns:\n",
        "      List[Dict]: List of dictionaries. Each dictionary \n",
        "        contains the parsed plain-text, hyperlinks for the section, word \n",
        "          frequencies excluding 'stop words'.\n",
        "    '''\n",
        "\n",
        "    for section in parsed_sections:\n",
        "        # tokenize text\n",
        "        token_list = section['text'].lower().split()\n",
        "\n",
        "        # remove stop words\n",
        "        for stop_word in stopwords.words('english'):\n",
        "            token_list = [token for token in token_list if token != stop_word]\n",
        "\n",
        "        # remove punctuation\n",
        "        punctuation = list('.,\\'\\\"')\n",
        "        for i in punctuation:\n",
        "            token_list = [token.replace(i, '') for token in token_list]\n",
        "\n",
        "        # compute word frequencies\n",
        "        word_frequencies = defaultdict(int)\n",
        "        for token in token_list:\n",
        "            word_frequencies[token] += 1\n",
        "        # sort word frequencies in descending order\n",
        "        word_frequencies = sorted(word_frequencies.items(), key=itemgetter(1), reverse = True)\n",
        "        section['frequencies'] = dict(word_frequencies)\n",
        "\n",
        "    return parsed_sections\n",
        "\n",
        "\n",
        "def display_piecharts(parsed_sections:List[Dict], frequency_cutoff:int=0, group_below_cutoff:bool=False, remove_below_cutoff:bool=False, num_sections_to_show:int=5) -> None:\n",
        "    '''\n",
        "    Displays parsed information from Wikipedia page in a pie chart using given\n",
        "    specifications.\n",
        "\n",
        "    Args:\n",
        "        parsed_sections (List[Dict]): List of dictionaries. Each dictionary \n",
        "          contains the parsed plain-text and hyperlinks for the section.\n",
        "        frequency_cutoff (int): Value used to determine how to remove or group \n",
        "          words words based on their frequency. Defaults to 0.\n",
        "        group_below_cutoff (bool): Specifies whether or not to group words that \n",
        "          have frequencies that are equal to or below the cutoff value into a \n",
        "          single group. Defaults to False.\n",
        "        remove_below_cutoff (bool): Specifies whether or not to remove words\n",
        "          that have frequencies that are equal to or below the cutoff value.\n",
        "          Defaults to False.\n",
        "        num_sections_to_show (int): Specifies the number of sections to display\n",
        "          graphs for. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    '''\n",
        "\n",
        "    for section in parsed_sections[:num_sections_to_show]:\n",
        "        word_frequencies = dict(section['frequencies'].items())\n",
        "\n",
        "        # find words with frequencies below frequency_cutoff\n",
        "        if frequency_cutoff != 0:\n",
        "            words_below_cutoff = [token for token in word_frequencies.items() if token[1] <= frequency_cutoff]\n",
        "\n",
        "            # remove words with frequencies below frequency_cutoff\n",
        "            if remove_below_cutoff or group_below_cutoff:\n",
        "                # combine words with frequencies below frequency_cutoff into one group\n",
        "                if group_below_cutoff:\n",
        "                    word_frequencies['grouped_words'] = sum([token[1] for token in words_below_cutoff])\n",
        "\n",
        "                for key, _ in words_below_cutoff:\n",
        "                    del word_frequencies[key]\n",
        "\n",
        "        # compute percentages to display on pie chart\n",
        "        total_words = sum(word_frequencies.values())\n",
        "        for word in word_frequencies:\n",
        "            word_frequencies[word] = (word_frequencies[word]/total_words) * 100\n",
        "        \n",
        "        # graph pie chart\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_axes([0,0,2,2])\n",
        "        ax.pie(word_frequencies.values(), labels=word_frequencies.keys(), autopct='%1.1f%%')\n",
        "        ax.set_title(f'Section: {section[\"title\"]}')\n",
        "        plt.show()\n",
        "\n",
        "def display_barcharts(parsed_sections:List[Dict], frequency_cutoff:int=0, group_below_cutoff:bool=False, remove_below_cutoff:bool=False, num_sections_to_show:int=5) -> None:\n",
        "    '''\n",
        "    Displays parsed information from Wikipedia page in a bar chart using given\n",
        "    specifications.\n",
        "\n",
        "    Args:\n",
        "        parsed_sections (List[Dict]): List of dictionaries. Each dictionary \n",
        "          contains the parsed plain-text and hyperlinks for the section.\n",
        "        frequency_cutoff (int): Value used to determine how to remove or group \n",
        "          words words based on their frequency. Defaults to 0.\n",
        "        group_below_cutoff (bool): Specifies whether or not to group words that \n",
        "          have frequencies that are equal to or below the cutoff value into a \n",
        "          single group. Defaults to False.\n",
        "        remove_below_cutoff (bool): Specifies whether or not to remove words\n",
        "          that have frequencies that are equal to or below the cutoff value.\n",
        "          Defaults to False.\n",
        "        num_sections_to_show (int): Specifies the number of sections to display\n",
        "          graphs for. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    '''\n",
        "\n",
        "    for section in parsed_sections[:num_sections_to_show]:\n",
        "        word_frequencies = dict(section['frequencies'].items())\n",
        "\n",
        "        # find words with frequencies below frequency_cutoff\n",
        "        if frequency_cutoff != 0:\n",
        "            words_below_cutoff = [token for token in word_frequencies.items() if token[1] <= frequency_cutoff]\n",
        "\n",
        "            # remove words with frequencies below frequency_cutoff\n",
        "            if remove_below_cutoff or group_below_cutoff:\n",
        "                # combine words with frequencies below frequency_cutoff into one group\n",
        "                if group_below_cutoff:\n",
        "                    word_frequencies['grouped_words'] = sum([token[1] for token in words_below_cutoff])\n",
        "\n",
        "                for key, _ in words_below_cutoff:\n",
        "                    del word_frequencies[key]\n",
        "\n",
        "        # graph bar chart\n",
        "        fig = plt.figure(figsize=(15, 4.8))\n",
        "        ax = fig.add_axes([0,0,1,1])\n",
        "        ax.bar(word_frequencies.keys(), word_frequencies.values())\n",
        "        ax.set_title(f'Section: {section[\"title\"]}')\n",
        "        plt.show()\n",
        "  \n",
        "def display_wordclouds(parsed_sections:List[Dict], frequency_cutoff:int=0, group_below_cutoff:bool=False, remove_below_cutoff:bool=False, num_sections_to_show:int=5) -> None:\n",
        "    '''\n",
        "      Displays parsed information from Wikipedia page in a word cloud using given\n",
        "      specifications.\n",
        "\n",
        "      Args:\n",
        "          parsed_sections (List[Dict]): List of dictionaries. Each dictionary \n",
        "            contains the parsed plain-text and hyperlinks for the section.\n",
        "          frequency_cutoff (int): Value used to determine how to remove or group \n",
        "            words words based on their frequency. Defaults to 0.\n",
        "          group_below_cutoff (bool): Specifies whether or not to group words that \n",
        "            have frequencies that are equal to or below the cutoff value into a \n",
        "            single group. Defaults to False.\n",
        "          remove_below_cutoff (bool): Specifies whether or not to remove words\n",
        "            that have frequencies that are equal to or below the cutoff value.\n",
        "            Defaults to False.\n",
        "          num_sections_to_show (int): Specifies the number of sections to display\n",
        "            graphs for. Defaults to 5.\n",
        "\n",
        "      Returns:\n",
        "        None\n",
        "    '''\n",
        "\n",
        "    for section in parsed_sections[:num_sections_to_show]:\n",
        "          word_frequencies = dict(section['frequencies'].items())\n",
        "\n",
        "          # find words with frequencies below frequency_cutoff\n",
        "          if frequency_cutoff != 0:\n",
        "              words_below_cutoff = [token for token in word_frequencies.items() if token[1] <= frequency_cutoff]\n",
        "\n",
        "              # remove words with frequencies below frequency_cutoff\n",
        "              if remove_below_cutoff or group_below_cutoff:\n",
        "                  # combine words with frequencies below frequency_cutoff into one group\n",
        "                  if group_below_cutoff:\n",
        "                      word_frequencies['grouped_words'] = sum([token[1] for token in words_below_cutoff])\n",
        "\n",
        "                  for key, _ in words_below_cutoff:\n",
        "                      del word_frequencies[key]\n",
        "\n",
        "          section_text = []\n",
        "          for word, freq in word_frequencies.items():\n",
        "              for f in range(freq):\n",
        "                  section_text.append(word)\n",
        "          section_text = ' '.join(section_text)\n",
        "\n",
        "          # generate WordCloud image\n",
        "          wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                min_font_size = 10).generate(section_text)\n",
        "\n",
        "          # plot the WordCloud image                      \n",
        "          plt.figure(figsize = (8, 8), facecolor = None)\n",
        "          plt.title(f'Section: {section[\"title\"]}')\n",
        "          plt.imshow(wordcloud)\n",
        "          \n",
        "          plt.axis(\"off\")\n",
        "          plt.tight_layout(pad = 0)\n",
        "          \n",
        "          plt.show()\n",
        "  \n",
        "def display_rawdata(parsed_sections:List[Dict], num_sections_to_show:int=5) -> None:\n",
        "    '''\n",
        "        Displays parsed information from Wikipedia page.\n",
        "\n",
        "        Args:\n",
        "            parsed_sections (List[Dict]): List of dictionaries. Each dictionary \n",
        "              contains the parsed plain-text and hyperlinks for the section.\n",
        "            num_sections_to_show (int): Specifies the number of sections to display\n",
        "              graphs for. Defaults to 5.\n",
        "\n",
        "        Returns:\n",
        "          None\n",
        "    '''\n",
        "\n",
        "    for section in parsed_sections[:num_sections_to_show]:\n",
        "        print(f\"Section: {section['title']}\")\n",
        "        print(f\"Word frequencies for section: {section['title']}\")\n",
        "        for word, freq in section['frequencies'].items():\n",
        "            print(f\"\\t{word} - {freq}\")\n",
        "        print(f\"Hyperlinks for section: {section['title']}\")\n",
        "        for i in section['hyperlinks']:\n",
        "            print(f\"\\t{i}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZSFUYEpb_Da"
      },
      "source": [
        "# Wikipedia URL to be parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU_FNmhjbmbK"
      },
      "outputs": [],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/google'\n",
        "parsed_sections = load_page(url)\n",
        "parsed_sections = digest_page(parsed_sections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgiJRNnTCX_1"
      },
      "source": [
        "# Display raw data\n",
        "First line will be the section title, next will be the section's hyperlinks, and last will be the sections word frequencies.\n",
        "Note only shows the first 5 sections, this can easily be changed through the argument 'num_sections_to_show'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO9Jh16JCbsW",
        "outputId": "3a607290-3d71-4bc5-cdea-280a79c863a7"
      },
      "outputs": [],
      "source": [
        "display_rawdata(parsed_sections, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARy_0ASPghVX"
      },
      "source": [
        "# Using bar graph to show word frequencies\n",
        "Note will only shows the first 5 sections, this can easily be changed through the argument 'num_sections_to_show'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIdPcRVjgjPx"
      },
      "source": [
        "## Display raw data as on bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XnfzC_vNg4mJ",
        "outputId": "2bbc5b96-1b36-491b-d114-97b2fb83811b"
      },
      "outputs": [],
      "source": [
        "display_barcharts(parsed_sections, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaoys-9jgqaZ"
      },
      "source": [
        "## Removing words with low frequency from dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrrZ7BPGiWe-"
      },
      "source": [
        "### Removing words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DA0-hn43ipAH",
        "outputId": "9a7cbc93-2c01-4a68-806e-97487f5e5819"
      },
      "outputs": [],
      "source": [
        "display_barcharts(parsed_sections, frequency_cutoff=2, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrAgbccciaZs"
      },
      "source": [
        "### Removing words with frequency of 4 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VeqmYvwniq8A",
        "outputId": "26677e9e-9a50-4a5a-d6a7-88c99444f19a"
      },
      "outputs": [],
      "source": [
        "display_barcharts(parsed_sections, frequency_cutoff=4, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGmq1qi4g1Kp"
      },
      "source": [
        "## Grouping together words with low frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTA2sDp8ihQq"
      },
      "source": [
        "### Grouping words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HPAsstX5iwIg",
        "outputId": "ff10a9bb-e265-4611-bee4-a993c231b1fb"
      },
      "outputs": [],
      "source": [
        "display_barcharts(parsed_sections, frequency_cutoff=2, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7j0YlNaijsg"
      },
      "source": [
        "### Grouping words with frequency of 4 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K4ISPjdLiypy",
        "outputId": "810fce5f-e681-4781-e51d-b5ff7db61f99"
      },
      "outputs": [],
      "source": [
        "display_barcharts(parsed_sections, frequency_cutoff=4, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-XnfroCbmbL"
      },
      "source": [
        "# Using a pie chart to represent word frequencies as percentages of the whole page\n",
        "Note will only shows the first 5 sections, this can easily be changed through the argument 'num_sections_to_show'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPZyYTaYenBP"
      },
      "source": [
        "### Display raw data as on pie chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lalRjsJOeqGg",
        "outputId": "11a09e6f-6598-4bc7-9694-38d43a09bb79"
      },
      "outputs": [],
      "source": [
        "display_piecharts(parsed_sections, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F0_AVqldghF"
      },
      "source": [
        "## Removing words with low frequency from dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsGeRP0c7rZ"
      },
      "source": [
        "### Removing words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G7SjxxvmbmbL",
        "outputId": "2ae47ab1-4300-47e4-ff0b-c1a8244f2899"
      },
      "outputs": [],
      "source": [
        "display_piecharts(parsed_sections, frequency_cutoff=2, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3rJeeFdc1H_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKR-OIPZc9zu"
      },
      "source": [
        "### Removing words with frequency of 4 and less\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u7EBcrexdSm5",
        "outputId": "2d6c7b53-0de5-4b0a-bac4-56567ef1790a"
      },
      "outputs": [],
      "source": [
        "display_piecharts(parsed_sections, frequency_cutoff=4, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnaLOR0Rdqpp"
      },
      "source": [
        "## Grouping together words with low frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erkQpQmZdLbZ"
      },
      "source": [
        "### Grouping words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ctDfsUdWe6v-",
        "outputId": "ecea6907-7db0-4b70-db9f-d1f59189d1b4"
      },
      "outputs": [],
      "source": [
        "display_piecharts(parsed_sections, frequency_cutoff=2, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ9ZCJvgdONZ"
      },
      "source": [
        "### Grouping words with frequency of 4 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0YINsMeGfRWI",
        "outputId": "d539106f-1990-43d9-98a3-f313b4fcc564"
      },
      "outputs": [],
      "source": [
        "display_piecharts(parsed_sections, frequency_cutoff=4, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na4fSNeY3-M8"
      },
      "source": [
        "# Using a word cloud to compare frequencies relatively to one another\n",
        "Note will only shows the first 5 sections, this can easily be changed through the argument 'num_sections_to_show'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdx1T9LT7zb-"
      },
      "source": [
        "## Display raw data on word cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zsxm1Ww64BEv",
        "outputId": "390ac6c1-ce6c-442e-fcc0-ba064779f9e8"
      },
      "outputs": [],
      "source": [
        "display_wordclouds(parsed_sections, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwUw6Lj170zn"
      },
      "source": [
        "## Removing words with low frequency from dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomuQX4074N9"
      },
      "source": [
        "### Removing words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ywGFNjCc8JDU",
        "outputId": "8f8b6596-fe8f-45ee-d730-da439c9c20eb"
      },
      "outputs": [],
      "source": [
        "display_wordclouds(parsed_sections, frequency_cutoff=2, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLaoNCt477Wp"
      },
      "source": [
        "### Removing words with frequency of 4 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQ30-Tj68TKn",
        "outputId": "6ba888b7-23e4-4bc1-be7d-22bb808dcfa5"
      },
      "outputs": [],
      "source": [
        "display_wordclouds(parsed_sections, frequency_cutoff=4, remove_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DjywS-Y78Xr"
      },
      "source": [
        "## Grouping together words with low frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOx72I738DHK"
      },
      "source": [
        "### Grouping words with frequency of 2 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iCCsumhF8V85",
        "outputId": "c593a645-894e-46ff-b2bc-51aba58d4eb6"
      },
      "outputs": [],
      "source": [
        "display_wordclouds(parsed_sections, frequency_cutoff=2, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6uHu7sl8HHo"
      },
      "source": [
        "### Grouping words with frequency of 4 and less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JxJT2Fwi8XKy",
        "outputId": "14e48e1f-7b29-43a5-b229-34ee6b4bda12"
      },
      "outputs": [],
      "source": [
        "display_wordclouds(parsed_sections, frequency_cutoff=4, group_below_cutoff=True, num_sections_to_show=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Dennis Tang - WikipediaDigester.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
